{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chief-investment",
   "metadata": {},
   "source": [
    "## Using spacy word embeddings\n",
    "https://spacy.io/usage/embeddings-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "silver-counter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      company                                          headlines  \\\n",
      "0         CCL  Carnival Corp. stock outperforms market on str...   \n",
      "1         CCL  Reasons To Avoid Carnival Stock At Current Levels   \n",
      "2         CCL  Amid vaccine hurdles, EU battles to save summe...   \n",
      "3         CCL     American Airlines Joins Debt-Market Behemoths    \n",
      "4         CCL  Carnival Corp. stock falls Tuesday, underperfo...   \n",
      "...       ...                                                ...   \n",
      "28204    SNOW              Snowflake Will Have to Run Extra Hot    \n",
      "28205    SNOW                   62 Biggest Movers From Yesterday   \n",
      "28206    SNOW  Sumo Logic Prices IPO Above Indicated Range, I...   \n",
      "28207    SNOW               Snowflake’s Stock Price Soars in IPO   \n",
      "28208    SNOW  Snowflake Stock: What You Need to Know About T...   \n",
      "\n",
      "                                               summaries  Headline score  \\\n",
      "0      Shares of Carnival Corp. rallied 2.41% to $28....          0.5106   \n",
      "1      Cruise industry recovery to pre-COVID levels i...         -0.2960   \n",
      "2      A \"digital green certificate” will be a proof ...          0.1531   \n",
      "3      Recent $10 billion financing transfers much of...          0.0000   \n",
      "4      Shares of Carnival Corp. slipped 5.17% to $28....          0.0000   \n",
      "...                                                  ...             ...   \n",
      "28204  Data warehousing provider’s soaring IPO puts i...          0.0000   \n",
      "28205  Gainers\\n\\nSnowflake Inc. (NYSE: SNOW) shares ...          0.0000   \n",
      "28206  Sumo Logic Inc (NASDAQ: SUMO) priced its initi...          0.0000   \n",
      "28207  Snowflake’s shares made their debut at $245 a ...          0.0000   \n",
      "28208  The data-management company’s strong revenue g...          0.0000   \n",
      "\n",
      "       Summary score  headline label  summary label  \n",
      "0             0.7430               1              1  \n",
      "1            -0.2960              -1             -1  \n",
      "2            -0.0258               1             -1  \n",
      "3            -0.3182               0             -1  \n",
      "4            -0.3612               0             -1  \n",
      "...              ...             ...            ...  \n",
      "28204         0.2023               0              1  \n",
      "28205         0.5267               0              1  \n",
      "28206         0.0000               0              0  \n",
      "28207         0.5267               0              1  \n",
      "28208         0.7096               0              1  \n",
      "\n",
      "[28209 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "class CompleteData:\n",
    "    def __init__(self):\n",
    "        avadata = open(\"data_2020-04-01_2021-03-26.pkl\", \"rb\")\n",
    "        self.data = pickle.load(avadata)\n",
    "        \n",
    "#         self.time = self.data[\"time\"]\n",
    "        self.company = self.data[\"related\"]\n",
    "        self.headlines = self.data[\"headline\"]\n",
    "        self.summary = self.data[\"summary\"]\n",
    "        \n",
    "        comp_list = [i for i in self.data[\"related\"]]\n",
    "        head_list = [i for i in self.headlines]\n",
    "        summ_list = [i for i in self.summary]\n",
    "        \n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        score_headline = []\n",
    "        score_summ = []\n",
    "        label_head = []\n",
    "        label_summ = []\n",
    "        \n",
    "        for sent in self.headlines:\n",
    "    #     print(sent)\n",
    "            marks = sia.polarity_scores(sent)\n",
    "        #     print(marks[\"compound\"])\n",
    "            score_headline.append(marks[\"compound\"])\n",
    "            if marks[\"compound\"] == 0:\n",
    "                label_head.append(0)\n",
    "            elif marks[\"compound\"] > 0:\n",
    "                label_head.append(1)\n",
    "            elif marks[\"compound\"] < 0:\n",
    "                label_head.append(-1)\n",
    "                \n",
    "        for sent in self.summary:\n",
    "        #     print(sent)\n",
    "            marks = sia.polarity_scores(sent)\n",
    "        #     print(marks[\"compound\"])\n",
    "            score_summ.append(marks[\"compound\"])\n",
    "            if marks[\"compound\"] == 0:\n",
    "                label_summ.append(0)\n",
    "            elif marks[\"compound\"] > 0:\n",
    "                label_summ.append(1)\n",
    "            elif marks[\"compound\"] < 0:\n",
    "                label_summ.append(-1)\n",
    "\n",
    "        self.df_head = pd.DataFrame({\"headlines\": head_list})\n",
    "        self.df_sums = pd.DataFrame({\"summaries\": summ_list})\n",
    "        self.df_headscore = pd.DataFrame({\"headlines score\": score_headline})\n",
    "        self.df_sumscore = pd.DataFrame({\"summaries score\": score_summ})\n",
    "        self.df_headlab = pd.DataFrame({\"headline label\": label_head})\n",
    "        self.df_summlab = pd.DataFrame({\"summary label\": label_summ})\n",
    "        \n",
    "        \n",
    "        self.compdata = pd.DataFrame({\"company\": comp_list})\n",
    "        \n",
    "        frames = [self.company, self.headlines, self.summary]\n",
    "        self.newsdata = pd.concat(frames, axis=1, ignore_index=True)\n",
    "        self.newsdata.columns = [\"company\", \"headlines\", \"summary\"]\n",
    "        \n",
    "        frame2 = [self.compdata, self.df_head, self.df_sums, self.df_headscore, \n",
    "                  self.df_sumscore , self.df_headlab , self.df_summlab]\n",
    "        self.scoredata = pd.concat(frame2, axis=1, ignore_index=True)\n",
    "        self.scoredata.columns = [\"company\", \"headlines\", \"summaries\", \"Headline score\", \n",
    "                                  \"Summary score\", \"headline label\", \"summary label\"]\n",
    "        \n",
    "#         self.combined = pd.concat([self.newsdata, self.scoredata], axis=1, ignore_index=True)\n",
    "#         self.combined.columns = [\"company\", \"headlines\", \"summary\", \"Headline score\", \"Summary score\"]\n",
    "cd = CompleteData()\n",
    "# print(cd.data)\n",
    "# print(cd.newsdata.head())\n",
    "print(cd.scoredata)\n",
    "# print(cd.combined)\n",
    "# print(type(cd.company))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "radical-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_write = open(\"all_senti.pkl\", \"wb\")\n",
    "pickle.dump(cd.scoredata, file_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-robert",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quality-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "import spacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "guilty-kelly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9ca34af62bc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Vectorization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Using Tfidf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "class predictors(TransformerMixin):\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1)) \n",
    "classifier = LinearSVC()\n",
    "# Using Tfidf\n",
    "tfvectorizer = TfidfVectorizer(tokenizer = spacy_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = [self.compdata, self.df_head, \n",
    "          self.df_sums, self.df_headscore, self.df_sumscore]\n",
    "\n",
    "cd.df_head = headlines\n",
    "cd.df_sums = summaries\n",
    "cd.df_headscore = headscore\n",
    "self.df_sumscore = sumscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(headlines, headscore, test_size=0.2, random_state=42)\n",
    "pipe_countvect = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-mattress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "conventional-reliance",
   "metadata": {},
   "source": [
    "NLP on news data (CCL first)\n",
    "Tutorial: https://realpython.com/natural-language-processing-spacy-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "caring-characteristic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reasons', 'To', 'Avoid', 'Carnival', 'Stock', 'At', 'Current', 'Levels']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "headline_list = cd.headlines.tolist()\n",
    "summary_list = cd.summary.tolist()\n",
    "\n",
    "\n",
    "head_doc = nlp(headline_list[1])\n",
    "summ_doc = nlp(summary_list[0])\n",
    "\n",
    "\n",
    "print ([token.text for token in head_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "emotional-consultation",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-479af964c5ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#     return proc_head, proc_summ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_headsum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_sumsum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mprocc_head\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mprocc_summ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-479af964c5ea>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0msumm_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mdoc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltering_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumm_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mdoc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlemmatizing_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    988\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.set_annotations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\pipeline\\_parser_internals\\ner.pyx\u001b[0m in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.set_annotations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.SetEntsDefault.values\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\enum.py\u001b[0m in \u001b[0;36m__members__\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_member_names_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__members__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def filtering_token(doc):\n",
    "    return [token for token in doc if not token.is_stop and not token.is_punct]\n",
    "def lemmatizing_token(doc):\n",
    "    return [token.lemma_.lower().strip() for token in doc]\n",
    "\n",
    "headline_list = cd.headlines.tolist()\n",
    "summary_list = cd.summary.tolist()\n",
    "# removing stop words & punctuations\n",
    "# test_doc_filt = Token.filtering_token(head_doc)\n",
    "# print(test_doc_filt)\n",
    "# normalizing\n",
    "# lem_doc = Token.lemmatizing_token(test_doc_filt)\n",
    "# print(lem_doc)\n",
    "def preprocess():\n",
    "    proc_head = pd.DataFrame([])\n",
    "    proc_summ = pd.DataFrame([])\n",
    "    head_list = []\n",
    "    summ_list = []\n",
    "    \n",
    "    for i in range(len(headline_list)):\n",
    "        head_doc = nlp(headline_list[i])\n",
    "        doc1 = filtering_token(head_doc)\n",
    "        doc2 = lemmatizing_token(doc1)\n",
    "        proc_head = ' '.join(doc2)\n",
    "#         proc_head = proc_head.append(pd.DataFrame(doc2), ignore_index=True)\n",
    "#         for data in proc_head:\n",
    "        head_list.append(proc_head)\n",
    "        \n",
    "        \n",
    "    for i in range(len(summary_list)):\n",
    "        summ_doc = nlp(summary_list[i])\n",
    "        doc1 = filtering_token(summ_doc)\n",
    "        doc2 = lemmatizing_token(doc1)\n",
    "        proc_summ = ' '.join(doc2)\n",
    "#         proc_summ = proc_summ.append(pd.DataFrame(doc2), ignore_index=True)\n",
    "#         for data in proc_summ:\n",
    "        summ_list.append(proc_summ)\n",
    "    \n",
    "    df_headsum = pd.DataFrame({\"Headlines\": head_list})\n",
    "    df_sumsum = pd.DataFrame({\"Summaries\": summ_list})\n",
    "    del head_list, summ_list\n",
    "#     return proc_head, proc_summ \n",
    "    return df_headsum, df_sumsum\n",
    "procc_head = preprocess()[0]\n",
    "procc_summ = preprocess()[1]\n",
    "\n",
    "print(procc_head)\n",
    "print(procc_summ)\n",
    "\n",
    "# print(procc_head)\n",
    "# print(procc_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "western-wayne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   headlines score\n",
      "0           0.5106\n",
      "1          -0.2960\n",
      "2           0.1531\n",
      "3           0.0000\n",
      "4           0.0000\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "score_headline = []\n",
    "score_summ = []\n",
    "\n",
    "for sent in cd.headlines:\n",
    "#     print(sent)\n",
    "    marks = sia.polarity_scores(sent)\n",
    "#     print(marks[\"compound\"])\n",
    "    score_headline.append(marks[\"compound\"])\n",
    "    \n",
    "    \n",
    "for sent in cd.summary:\n",
    "#     print(sent)\n",
    "    marks = sia.polarity_scores(sent)\n",
    "#     print(marks[\"compound\"])\n",
    "    score_summ.append(marks[\"compound\"])\n",
    "    \n",
    "    \n",
    "df_headscore = pd.DataFrame({\"headlines score\": score_headline})\n",
    "df_sumscore = pd.DataFrame({\"summaries score\": score_summ})\n",
    "\n",
    "\n",
    "print(df_headscore.head())\n",
    "# print(df_sumscore.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "biblical-qatar",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-8c63b9c87be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_headscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_headscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# the_frames = [cd.newsdata, df_headscore[\"headlines score\"]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewsdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_headscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# frame1 = [df_headscore, df_sumscore]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# pd1 = pd.concat(the_frames, axis=1, ignore_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   8108\u001b[0m         \u001b[1;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8109\u001b[0m         \"\"\"\n\u001b[1;32m-> 8110\u001b[1;33m         return self._join_compat(\n\u001b[0m\u001b[0;32m   8111\u001b[0m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8112\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   8133\u001b[0m                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8134\u001b[0m                 )\n\u001b[1;32m-> 8135\u001b[1;33m             return merge(\n\u001b[0m\u001b[0;32m   8136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8137\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_index\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_index\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"asof\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 896\u001b[1;33m             join_index, left_indexer, right_indexer = left_ax.join(\n\u001b[0m\u001b[0;32m    897\u001b[0m                 \u001b[0mright_ax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\datetimelike.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_utc_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         return Index.join(\n\u001b[0m\u001b[0;32m    895\u001b[0m             \u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m   3667\u001b[0m             \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"O\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3668\u001b[0m             \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"O\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3669\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_indexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3671\u001b[0m         \u001b[0m_validate_join_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m   3681\u001b[0m                 )\n\u001b[0;32m   3682\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3683\u001b[1;33m                 return self._join_non_unique(\n\u001b[0m\u001b[0;32m   3684\u001b[0m                     \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3685\u001b[0m                 )\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_join_non_unique\u001b[1;34m(self, other, how, return_indexers)\u001b[0m\n\u001b[0;32m   3811\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_engine_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3813\u001b[1;33m         left_idx, right_idx = get_join_indexers(\n\u001b[0m\u001b[0;32m   3814\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3815\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1415\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m     )\n\u001b[1;32m-> 1417\u001b[1;33m     \u001b[0mzipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m     \u001b[0mllab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrlab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzipped\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1412\u001b[0m     \u001b[1;31m# get left & right join labels and num. of levels at each location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m     mapped = (\n\u001b[1;32m-> 1414\u001b[1;33m         \u001b[0m_factorize_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1415\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m     )\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_factorize_keys\u001b[1;34m(lk, rk, sort, how)\u001b[0m\n\u001b[0;32m   2062\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m         \u001b[0mllab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrlab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sort_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mllab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrlab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m     \u001b[1;31m# NA group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_sort_labels\u001b[1;34m(uniques, left, right)\u001b[0m\n\u001b[0;32m   2087\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2089\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2090\u001b[0m     \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2091\u001b[0m     \u001b[0mnew_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mllength\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mllength\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36msafe_sort\u001b[1;34m(values, codes, na_sentinel, assume_unique, verify)\u001b[0m\n\u001b[0;32m   2118\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"mixed-integer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m     ):\n\u001b[1;32m-> 2120\u001b[1;33m         \u001b[0mordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sort_mixed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36m_sort_mixed\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   2182\u001b[0m     \u001b[1;34m\"\"\" order ints before strings in 1d arrays, safe in py3 \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2183\u001b[0m     \u001b[0mstr_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2184\u001b[1;33m     \u001b[0mnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mstr_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2185\u001b[0m     \u001b[0mstrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2186\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msort\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "df_headscore = df_headscore.reset_index(drop=True)\n",
    "# the_frames = [cd.newsdata, df_headscore[\"headlines score\"]]\n",
    "pd1 = cd.newsdata.join(df_headscore)\n",
    "# frame1 = [df_headscore, df_sumscore]\n",
    "# pd1 = pd.concat(the_frames, axis=1, ignore_index=True)\n",
    "print(pd1)\n",
    "# print(cd.newsdata)\n",
    "# pd1 = pd1.reset_index(drop=True)\n",
    "# result_pd = pd.concat([cd.newsdata, pd1[\"headlines score\"], pd1[\"summaries score\"]], axis=1, ignore_index=True)\n",
    "# print(result_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "circular-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-wallpaper",
   "metadata": {},
   "source": [
    "### Trying with SVM \n",
    "https://mahadev001.github.io/Mahadev-Upadhyayula/Sentiment%20Analysis%20via%20NLP/Sentiment%20Analysis%20using%20NLP%20with%20Spacy%20and%20%20SVM.html\n",
    "https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
    "https://realpython.com/python-nltk-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "economic-anderson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emerging-focus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download() ## downloaded everything in the pop-up window\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-socket",
   "metadata": {},
   "source": [
    "### Transformer models: cant do coz computer too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "english-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "CuPy is not correctly installed.\n\nIf you are using wheel distribution (cupy-cudaXX), make sure that the version of CuPy you installed matches with the version of CUDA on your host.\nAlso, confirm that only one CuPy package is installed:\n  $ pip freeze\n\nIf you are building CuPy from source, please check your environment, uninstall CuPy and reinstall it with:\n  $ pip install cupy --no-cache-dir -vvvv\n\nCheck the Installation Guide for details:\n  https://docs.cupy.dev/en/latest/install.html\n\noriginal error: DLL load failed while importing runtime: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m             message='can\\'t resolve package from __spec__')\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minternal\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mcupy\\core\\core.pyx\u001b[0m in \u001b[0;36minit cupy.core.core\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\cuda\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_environment\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_cuda_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_nvcc_path\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompiler\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\cuda\\compiler.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mcupy\\cuda\\device.pyx\u001b[0m in \u001b[0;36minit cupy.cuda.device\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing runtime: The specified module could not be found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5ee8b06db92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# This prevents out-of-memory errors that would otherwise occur from competing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# memory pools.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mset_gpu_allocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pytorch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mrequire_gpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\thinc\\backends\\__init__.py\u001b[0m in \u001b[0;36mset_gpu_allocator\u001b[1;34m(allocator)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \"\"\"\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallocator\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"pytorch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0muse_pytorch_for_gpu_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mallocator\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tensorflow\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0muse_tensorflow_for_gpu_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\thinc\\backends\\__init__.py\u001b[0m in \u001b[0;36muse_pytorch_for_gpu_memory\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;32mor\u001b[0m \u001b[0mvice\u001b[0m \u001b[0mversa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mdo\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcurrently\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mimplementation\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0massert_pytorch_installed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\cupy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m original error: {}'''.format(_exc_info[1]))  # NOQA\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_msg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: CuPy is not correctly installed.\n\nIf you are using wheel distribution (cupy-cudaXX), make sure that the version of CuPy you installed matches with the version of CUDA on your host.\nAlso, confirm that only one CuPy package is installed:\n  $ pip freeze\n\nIf you are building CuPy from source, please check your environment, uninstall CuPy and reinstall it with:\n  $ pip install cupy --no-cache-dir -vvvv\n\nCheck the Installation Guide for details:\n  https://docs.cupy.dev/en/latest/install.html\n\noriginal error: DLL load failed while importing runtime: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from thinc.api import set_gpu_allocator, require_gpu\n",
    "\n",
    "# Use the GPU, with memory allocations directed via PyTorch.\n",
    "# This prevents out-of-memory errors that would otherwise occur from competing\n",
    "# memory pools.\n",
    "set_gpu_allocator(\"pytorch\")\n",
    "require_gpu(0)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "for doc in nlp.pipe([\"some text\", \"some other text\"]):\n",
    "    tokvecs = doc._.trf_data.tensors[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-summit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
